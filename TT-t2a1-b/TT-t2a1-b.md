# Tom Tutone T2A1-B Workbook Part B

## Q1. Identify and explain the workings of TWO sorting algorithms and discuss and compare their performance/efficiency (i.e. Big O)

Two common types of sorting algorithms are the bubble sort and merge sort methods.

The bubble sort method works by taking one value from a set, a considered value, and comparing it to each other value in the set, from left to right. If the considered value is larger than a value it is compared against, the two values switch places. If not, the values do not swap places. This process continues until all other values have been compared against the considered value. The next value in the original set is then considered and compared against every other value. Once every value has been considered, the list is sorted from smallest to largest.

Bubble sorting is an infamously inefficient sorting method because it does not draw logical conclusions as it proceeds and must sometimes make comparisons that are unneccesary. For example, even if the smallest value in an array is considered last, it will still be compared to every other value. A bubble sort function can be coded by using a loop which iterates through the input set to consider each value and a nested loop which iterates through the set again to compare the considered value against each other value. Because the outer loop iterates through every value, it has a complexity of _n_ where _n_ is the number of input values. The inner loop has the same complexity and, because the inner loop is called for each outer loop, these two values multiply meaning a Big O notation of _n^2_.

Merge sort is an alternative sorting method that is more complex to program but more efficient. A merge sort first continually halves a set until it is fractioned into single values. The singular fractions are then paired up, compared and the smaller value is placed on the left creating a new, combined and sorted fraction. The function then pairs up these new fractions and begins comparing them. At this next comparison step, the first index in each fraction is compared. Whichever value is smaller is recorded in an output list and the next indexed value from its fraction is compared against the value that was not added to the output list. This loop continues until there are no more values to compare the final, largest value against and it is added to the output fraction at its right-most end. This process of merging fractions and comparing their indexes continues until the original set has been reassembled, now, completely sorted.

Each halving step takes a constant amount of time so this step is disregarded in terms of Big O notation. The sorting method must be called for each fraction and the number of fractions is relative to the number of times the original set was initially halved, a relationship that can be expressed as $log{_2}{n}$/. The merging step requires interating through each value, a Big O complexity of _n_. Because the sorting method is at each merge, the complexities multiply meaning a Big O notation of n$log{_2}{n}$/ (Khan Academy, n.d.).

In terms of complexity, bubble sort and merge sort have different strengths. Bubble sort is advantageous because it is easy to program and can function quickly with small sets of values. However, as the number of values to be sorted increases, the complexity rapidly scales, a significant disavantage. Alternatively, merge sort requires thoughtful programming and, because it has a logarithmic complexity, requires a relatively high amount of computing power to sort a small data set. Yet, as a logarithmic diagram reveals, merge sort becomes significantly more efficient compared to a quadratic function as the number of values to be sorted increases. This tipping point of efficiency comes quickly and, in most cases, merge sort should be the preferred sorting method. It is also worth noting that merge sort requires more memory to execute than a bubble sort because each fraction and sorted output has to be tracked before the merge sort concludes. If a developer had limited memory to execute a sort, they may sacrifice time and choose a bubble sort.

### References

Khan Academy (n.d.) _[Analysis of Merge Sort](https://www.khanacademy.org/computing/computer-science/algorithms/merge-sort/a/analysis-of-merge-sort)_, Khan Academy Website, accessed 2 July 2024.

## Q2. Identify and explain the workings of TWO search algorithms and discuss and compare their performance/efficiency (i.e. Big O)

Two complementary search algorithms are linear search and binary search.

Linear search is the process of iterating through a set and comparing each value to the desired value. If the compared value matches the desired value, the compared value is returned and the function ends.

Linear search is very simple to implement and can be applied to any data set in any state. Because a linear search may have to iterate through an entire set before it finds the desired index, it has a complexity of _n_ where _n_ is the number of values to be searched.

Binary search is distinct from linear search as it can only be used on sorted data sets. Binary search begins by considering the maximum and minimum indexes of a set and calculating their midpoint. The midpoint of an array or subarray can be calculated by summing the lowest index with the result of the highest index minus the lowest index, also known as the difference, and dividing this sum by two (rounding down to an integer). The value at the middle index of the set is then compared to the desired value. If these values are equal, the middle value is returned. If the desired value is lower than the value at the middle index, a subarray is next considered with the highest index being set to the calculated middle index minus one. If the desired value is higher, the lowest index is set to the middle index plus one. The loop then begins again with the updated subarray, finding the midpoint and comparing it to the desired value. Eventually, if the desired value exists in the set, the desired value will match the middle value and be returned.

In a binary search, the number of input values affects how many times the set may have to be halved to find the desired value. The relationship of halving the set a number of times relative to the input size means binary search has a Big O notation of $log{_2}{n}$/. Unlike merge sort, no additional function is applied upon each halving so the Big O notation of binary search is $log{_2}{n}$/ rather than _n_$log{_2}{n}$/.

Comparing linear search and binary search, there are apparent advantages to each. Linear search is useful because it is easy to program and can be applied to any set in any state without any preprocessing. However, the function does not have any steps that increases its efficiency as it continues. Binary search is much more efficient as the size of the input grows because it inherently eliminates large groups of incorrect answers at each loop. Binary search is not appropriate for all circumstances because it requires a sorted list input. A set would first need to be input into a sorting function before being input into the binary search function, meaning a developer must consider how long it takes to code and run two functions rather than one. Linear search is appropriate for small data sets or sets that are frequently changed without being sorted, whilst binary search should be considered and used when the set's size grows.

### References

GeeksforGeeks (2024) _[Binary Search Algorithm â€“ Iterative and Recursive Implementation](https://www.geeksforgeeks.org/binary-search/)_, GeeksforGeeks Website, accessed 3 July 2024.
